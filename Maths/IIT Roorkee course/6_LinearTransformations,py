Linear Transformations:

A linear transformation is a function between vector spaces that preserves vector addition and scalar multiplication. Suppose we have two vector spaces V and W over the same field (e.g., real numbers or complex numbers), and a function T: V → W. T is a linear transformation if, for all vectors u and v in V and any scalar c, the following properties hold:

Additivity:
T(u + v) = T(u) + T(v)
Homogeneity of Degree 1:
T(cu) = cT(u)
Example:
Consider T: R^2 → R^2 defined as T([x, y]) = [2x, 3y]. This transformation satisfies the linearity properties.

Rotation Matrix:
A rotation matrix is a specific type of linear transformation that rotates vectors in a plane. For a counterclockwise rotation by an angle θ in a 2D plane, the rotation matrix is given by:
R(θ) = | cos(θ)  -sin(θ) |
        | sin(θ)   cos(θ) |

This matrix transforms a vector [x, y] to a new vector after rotation.

Example:
For a 90-degree counterclockwise rotation, the rotation matrix is:
R(90°) = | 0  -1 |
         | 1   0 |

This matrix rotates vectors by 90 degrees counterclockwise.

Important Theorems:
Rank-Nullity Theorem:
For a linear transformation T: V → W, where V and W are vector spaces, the rank-nullity theorem states: dim(ker(T)) + dim(im(T)) = dim(V).

Inverse Transformation Theorem:
If T: V → W is a bijective linear transformation, then there exists a unique linear transformation T⁻¹: W → V such that T⁻¹ ∘ T = id_V and T ∘ T⁻¹ = id_W, where id_V and id_W are the identity transformations on V and W, respectively.

Determinant-Preserving Theorem (for 2D transformations):
If T: R^2 → R^2 is a linear transformation represented by the matrix A, and det(A) ≠ 0, then T preserves the area of parallelograms.
